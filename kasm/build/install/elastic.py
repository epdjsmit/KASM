#!/usr/bin/env python3 -tt
import os
import re
import subprocess
import time

configs = [
    "/usr/lib/systemd/system/elasticsearch.service",
    "/etc/elasticsearch/jvm.options",
    "/etc/elasticsearch/elasticsearch.yml",
    "/etc/kibana/kibana.yml",
]


def main():
    def replace_original_configs(configs):
        for config in configs:
            if os.path.exists(config):
                with open(config) as origs:
                    orig = origs.readlines()
                with open(config + ".orig", "w") as origfile:
                    for eachline in orig:
                        origfile.write(eachline)
            else:
                pass

    print(
        "\n\n  -> \033[1;36mCommencing Elastic Phase...\033[1;m\n  ----------------------------------------"
    )
    time.sleep(1)
    print("     elastic stack is not configured, please stand by...")
    subprocess.Popen(
        ["sudo", "/bin/systemctl", "daemon-reload"],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
    ).communicate()
    replace_original_configs(configs)
    with open("/etc/elasticsearch/elasticsearch.yml", "w") as eyml:
        eyml.write(
            '# ======================== Elasticsearch Configuration =========================\n#\n# NOTE: Elasticsearch comes with reasonable defaults for most settings.\n#       Before you set out to tweak and tune the configuration, make sure you\n#       understand what are you trying to accomplish and the consequences.\n#\n# The primary way of configuring a node is via this file. This template lists\n# the most important settings you may want to configure for a production cluster.\n#\n# Please consult the documentation for further information on configuration options:\n# https://www.elastic.co/guide/en/elasticsearch/reference/index.html\n#\n# ---------------------------------- Cluster -----------------------------------\n#\n# Use a descriptive name for your cluster:\n#\ncluster.name: elrond\n#\n# ------------------------------------ Node ------------------------------------\n#\n# Use a descriptive name for the node:\n#\nnode.name: elrond-es1\n#\n# Add custom attributes to the node:\n#\n#node.attr.rack: r1\n#\n# ----------------------------------- Paths ------------------------------------\n#\n# Path to directory where to store the data (separate multiple locations by comma):\n#\npath.data: /var/lib/elasticsearch\n#\n# Path to log files:\n#\npath.logs: /var/log/elasticsearch\n#\n# ----------------------------------- Memory -----------------------------------\n#\n# Lock the memory on startup:\n#\n#bootstrap.memory_lock: true\n#\n# Make sure that the heap size is set to about half the memory available\n# on the system and that the owner of the process is allowed to use this\n# limit.\n#\n# Elasticsearch performs poorly when the system is swapping the memory.\n#\n# ---------------------------------- Network -----------------------------------\n#\n# By default Elasticsearch is only accessible on localhost. Set a different\n# address here to expose this node on the network:\n#\nnetwork.host: 127.0.0.1\n#\n# By default Elasticsearch listens for HTTP traffic on the first free port it\n# finds starting at 9200. Set a specific HTTP port here:\n#\nhttp.port: 9200\n#\n# For more information, consult the network module documentation.\n#\n# --------------------------------- Discovery ----------------------------------\n#\n# Pass an initial list of hosts to perform discovery when this node is started:\n# The default list of hosts is ["127.0.0.1", "[::1]"]\n#\n#discovery.type: single-node\n#discovery.seed_hosts: ["host1", "host2"]\n#\n# Bootstrap the cluster using an initial set of master-eligible nodes:\n#\ncluster.initial_master_nodes: ["elrond-es1"]\n#\n# For more information, consult the discovery and cluster formation module documentation.\n#\n# ---------------------------------- Various -----------------------------------\n#\n# Require explicit names when deleting indices:\n#\n#action.destructive_requires_name: true\n#\n# ---------------------------------- Security ----------------------------------\n#\n#                                 *** WARNING ***\n#\n# Elasticsearch security features are not enabled by default.\n# These features are free, but require configuration changes to enable them.\n# This means that users donâ€™t have to provide credentials and can get full access\n# to the cluster. Network connections are also not encrypted.\n#\n# To protect your data, we strongly encourage you to enable the Elasticsearch security features. \n# Refer to the following documentation for instructions.\n#\n# https://www.elastic.co/guide/en/elasticsearch/reference/7.16/configuring-stack-security.html\n'
        )
    subprocess.Popen(
        ["sudo", "sysctl", "-w", "vm.max_map_count=262144"],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
    ).communicate()
    subprocess.Popen(
        ["sudo", "/bin/systemctl", "enable", "elasticsearch.service"],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
    ).communicate()
    subprocess.Popen(
        ["sudo", "systemctl", "start", "elasticsearch.service"],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
    ).communicate()
    subprocess.Popen(
        ["sudo", "chmod", "777", "/etc/systemd/system/logstash.service"],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
    ).communicate()
    with open("/etc/systemd/system/logstash.service", "w") as logstash_service:
        logstash_service.write(
            '[Unit]\nDescription=logstash\n\n[Service]\nType=simple\nUser=logstash\nGroup=logstash\n# Load env vars from /etc/default/ and /etc/sysconfig/ if they exist.\n# Prefixing the path with \'-\' makes it try to load, but if the file doesn\'t\n# exist, it continues onward.\nEnvironmentFile=-/etc/default/logstash\nEnvironmentFile=-/etc/sysconfig/logstash\nExecStart=/usr/share/logstash/bin/logstash "--path.settings" "/etc/logstash"\nRestart=always\nWorkingDirectory=/\nNice=19\nLimitNOFILE=16384\n\n# When stopping, how long to wait before giving up and sending SIGKILL?\n# Keep in mind that SIGKILL on a process can cause data loss.\nTimeoutStopSec=180\n\n[Install]\nWantedBy=multi-user.target\n'
        )
    subprocess.Popen(
        ["sudo", "chmod", "644", "/etc/systemd/system/logstash.service"],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
    ).communicate()
    subprocess.Popen(
        ["sudo", "systemctl", "enable", "logstash.service"],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
    ).communicate()
    subprocess.Popen(
        ["sudo", "systemctl", "start", "logstash.service"],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
    ).communicate()
    replace_original_configs(configs)
    with open("/etc/kibana/kibana.yml", "w") as kyml:
        kyml.write(
            '# Kibana is served by a back end server. This setting specifies the port to use.\nserver.port: 5601\n\n# Specifies the address to which the Kibana server will bind. IP addresses and host names are both valid values.\n# The default is \'localhost\', which usually means remote machines will not be able to connect.\n# To allow connections from remote users, set this parameter to a non-loopback address.\nserver.host: "127.0.0.1"\n\n# Enables you to specify a path to mount Kibana at if you are running behind a proxy.\n# Use the `server.rewriteBasePath` setting to tell Kibana if it should remove the basePath\n# from requests it receives, and to prevent a deprecation warning at startup.\n# This setting cannot end in a slash.\n#server.basePath: ""\n\n# Specifies whether Kibana should rewrite requests that are prefixed with\n# `server.basePath` or require that they are rewritten by your reverse proxy.\n# This setting was effectively always `false` before Kibana 6.3 and will\n# default to `true` starting in Kibana 7.0.\n#server.rewriteBasePath: false\n\n# Specifies the public URL at which Kibana is available for end users. If\n# `server.basePath` is configured this URL should end with the same basePath.\n#server.publicBaseUrl: ""\n\n# The maximum payload size in bytes for incoming server requests.\n#server.maxPayload: 1048576\n\n# The Kibana server\'s name.  This is used for display purposes.\nserver.name: "linux-kb1"\n\n# The URLs of the Elasticsearch instances to use for all your queries.\nelasticsearch.hosts: ["http://127.0.0.1:9200"]\n\n# Kibana uses an index in Elasticsearch to store saved searches, visualizations and\n# dashboards. Kibana creates a new index if the index doesn\'t already exist.\n#kibana.index: ".kibana"\n\n# The default application to load.\n#kibana.defaultAppId: "home"\n\n# If your Elasticsearch is protected with basic authentication, these settings provide\n# the username and password that the Kibana server uses to perform maintenance on the Kibana\n# index at startup. Your Kibana users still need to authenticate with Elasticsearch, which\n# is proxied through the Kibana server.\n#elasticsearch.username: "kibana_system"\n#elasticsearch.password: "pass"\n\n# Kibana can also authenticate to Elasticsearch via "service account tokens".\n# If may use this token instead of a username/password.\n# elasticsearch.serviceAccountToken: "my_token"\n\n# Enables SSL and paths to the PEM-format SSL certificate and SSL key files, respectively.\n# These settings enable SSL for outgoing requests from the Kibana server to the browser.\n#server.ssl.enabled: false\n#server.ssl.certificate: /path/to/your/server.crt\n#server.ssl.key: /path/to/your/server.key\n\n# Optional settings that provide the paths to the PEM-format SSL certificate and key files.\n# These files are used to verify the identity of Kibana to Elasticsearch and are required when\n# xpack.security.http.ssl.client_authentication in Elasticsearch is set to required.\n#elasticsearch.ssl.certificate: /path/to/your/client.crt\n#elasticsearch.ssl.key: /path/to/your/client.key\n\n# Optional setting that enables you to specify a path to the PEM file for the certificate\n# authority for your Elasticsearch instance.\n#elasticsearch.ssl.certificateAuthorities: [ "/path/to/your/CA.pem" ]\n\n# To disregard the validity of SSL certificates, change this setting\'s value to \'none\'.\n#elasticsearch.ssl.verificationMode: full\n\n# Time in milliseconds to wait for Elasticsearch to respond to pings. Defaults to the value of\n# the elasticsearch.requestTimeout setting.\n#elasticsearch.pingTimeout: 1500\n\n# Time in milliseconds to wait for responses from the back end or Elasticsearch. This value\n# must be a positive integer.\n#elasticsearch.requestTimeout: 30000\n\n# List of Kibana client-side headers to send to Elasticsearch. To send *no* client-side\n# headers, set this value to [] (an empty list).\n#elasticsearch.requestHeadersWhitelist: [ authorization ]\n\n# Header names and values that are sent to Elasticsearch. Any custom headers cannot be overwritten\n# by client-side headers, regardless of the elasticsearch.requestHeadersWhitelist configuration.\n#elasticsearch.customHeaders: {{'
        )
        kyml.write(
            '}}\n\n# Time in milliseconds for Elasticsearch to wait for responses from shards. Set to 0 to disable.\n#elasticsearch.shardTimeout: 30000\n\n# Logs queries sent to Elasticsearch. Requires logging.verbose set to true.\n#elasticsearch.logQueries: false\n\n# Specifies the path where Kibana creates the process ID file.\n#pid.file: /run/kibana/kibana.pid\n\n# Enables you to specify a file where Kibana stores log output.\n#logging.dest: stdout\n\n# Set the value of this setting to true to suppress all logging output.\n#logging.silent: false\n\n# Set the value of this setting to true to suppress all logging output other than error messages.\n#logging.quiet: false\n\n# Set the value of this setting to true to log all events, including system usage information\n# and all requests.\n#logging.verbose: false\n\n# Set the interval in milliseconds to sample system and process performance\n# metrics. Minimum is 100ms. Defaults to 5000.\n#ops.interval: 5000\n\n# Specifies locale to be used for all localizable strings, dates and number formats.\n# Supported languages are the following: English - en , by default , Chinese - zh-CN .\n#i18n.locale: "en"\n'
        )
    subprocess.Popen(
        ["sudo", "/bin/systemctl", "daemon-reload"],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
    ).communicate()
    subprocess.Popen(
        ["sudo", "systemctl", "enable", "kibana.service"],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
    ).communicate()
    subprocess.Popen(
        ["sudo", "systemctl", "start", "kibana.service"],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
    ).communicate()
    time.sleep(1)
    mem = int(
        re.findall(
            r"Mem:\s+(\d+)",
            str(
                subprocess.Popen(
                    ["free", "-b"], stdout=subprocess.PIPE, stderr=subprocess.PIPE
                ).communicate()
            ),
        )[0]
    )
    if mem:
        if mem < 2000000000:
            allocate = "256m"
        elif mem > 2000000000 and mem < 4000000000:
            allocate = "512m"
        elif mem > 4000000000 and mem < 6000000000:
            allocate = "750m"
        elif mem > 6000000000 and mem < 8000000000:
            allocate = "1024m"
        else:
            allocate = "2048m"
    else:
        pass
    with open("/usr/lib/systemd/system/elasticsearch.service", "w") as esvc:
        esvc.write(
            '[Unit]\nDescription=Elasticsearch\nDocumentation=https://www.elastic.co\nWants=network-online.target\nAfter=network-online.target\n\n[Service]\nType=notify\nRuntimeDirectory=elasticsearch\nPrivateTmp=true\nEnvironment=ES_HOME=/usr/share/elasticsearch\nEnvironment=ES_PATH_CONF=/etc/elasticsearch\nEnvironment=PID_DIR=/var/run/elasticsearch\nEnvironment=ES_SD_NOTIFY=true\nEnvironmentFile=-/etc/default/elasticsearch\n\nWorkingDirectory=/usr/share/elasticsearch\n\nUser=elasticsearch\nGroup=elasticsearch\n\nExecStart=/usr/share/elasticsearch/bin/systemd-entrypoint -p ${PID_DIR}/elasticsearch.pid --quiet\n\n# StandardOutput is configured to redirect to journalctl since\n# some error messages may be logged in standard output before\n# elasticsearch logging system is initialized. Elasticsearch\n# stores its logs in /var/log/elasticsearch and does not use\n# journalctl by default. If you also want to enable journalctl\n# logging, you can simply remove the "quiet" option from ExecStart.\nStandardOutput=journal\nStandardError=inherit\n\n# Specifies the maximum file descriptor number that can be opened by this process\nLimitNOFILE=65535\n\n# Specifies the maximum number of processes\nLimitNPROC=4096\n\n# Specifies the maximum size of virtual memory\nLimitAS=infinity\n\n# Specifies the maximum file size\nLimitFSIZE=infinity\n\n# Disable timeout logic and wait until process is stopped\nTimeoutStopSec=0\n\n# SIGTERM signal is used to stop the Java process\nKillSignal=SIGTERM\n\n# Send the signal only to the JVM rather than its control group\nKillMode=process\n\n# Java process is never killed\nSendSIGKILL=no\n\n# When a JVM receives a SIGTERM signal it exits with code 143\nSuccessExitStatus=143\n\n# Allow a slow startup before the systemd notifier module kicks in to extend the timeout\nTimeoutStartSec=500\n\n[Install]\nWantedBy=multi-user.target\n\n# Built for packages-7.17.1 (packages)\n'
        )
    with open("/etc/elasticsearch/jvm.options", "w") as ejvm:
        ejvm.write(
            "################################################################\n##\n## JVM configuration\n##\n################################################################\n##\n## WARNING: DO NOT EDIT THIS FILE. If you want to override the\n## JVM options in this file, or set any additional options, you\n## should create one or more files in the jvm.options.d\n## directory containing your adjustments.\n##\n## See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/jvm-options.html\n## for more information.\n##\n################################################################\n\n\n\n################################################################\n## IMPORTANT: JVM heap size\n################################################################\n##\n## The heap size is automatically configured by Elasticsearch\n## based on the available memory in your system and the roles\n## each node is configured to fulfill. If specifying heap is\n## required, it should be done through a file in jvm.options.d,\n## and the min and max should be set to the same value. For\n## example, to set the heap to 4 GB, create a new file in the\n## jvm.options.d directory containing these lines:\n##\n-Xms{}\n-Xmx{}\n##\n## See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/heap-size.html\n## for more information\n##\n################################################################\n\n\n################################################################\n## Expert settings\n################################################################\n##\n## All settings below here are considered expert settings. Do\n## not adjust them unless you understand what you are doing. Do\n## not edit them in this file; instead, create a new file in the\n## jvm.options.d directory containing your adjustments.\n##\n################################################################\n\n## GC configuration\n8-13:-XX:+UseConcMarkSweepGC\n8-13:-XX:CMSInitiatingOccupancyFraction=75\n8-13:-XX:+UseCMSInitiatingOccupancyOnly\n\n## G1GC Configuration\n# NOTE: G1 GC is only supported on JDK version 10 or later\n# to use G1GC, uncomment the next two lines and update the version on the\n# following three lines to your version of the JDK\n# 10-13:-XX:-UseConcMarkSweepGC\n# 10-13:-XX:-UseCMSInitiatingOccupancyOnly\n14-:-XX:+UseG1GC\n\n## JVM temporary directory\n-Djava.io.tmpdir=${}{}\n\n## heap dumps\n\n# generate a heap dump when an allocation from the Java heap fails; heap dumps\n# are created in the working directory of the JVM unless an alternative path is\n# specified\n-XX:+HeapDumpOnOutOfMemoryError\n\n# exit right after heap dump on out of memory error. Recommended to also use\n# on java 8 for supported versions (8u92+).\n9-:-XX:+ExitOnOutOfMemoryError\n\n# specify an alternative path for heap dumps; ensure the directory exists and\n# has sufficient space\n-XX:HeapDumpPath=/var/lib/elasticsearch\n\n# specify an alternative path for JVM fatal error logs\n-XX:ErrorFile=/var/log/elasticsearch/hs_err_pid%p.log\n\n## JDK 8 GC logging\n8:-XX:+PrintGCDetails\n8:-XX:+PrintGCDateStamps\n8:-XX:+PrintTenuringDistribution\n8:-XX:+PrintGCApplicationStoppedTime\n8:-Xloggc:/var/log/elasticsearch/gc.log\n8:-XX:+UseGCLogFileRotation\n8:-XX:NumberOfGCLogFiles=32\n8:-XX:GCLogFileSize=64m\n\n# JDK 9+ GC logging\n9-:-Xlog:gc*,gc+age=trace,safepoint:file=/var/log/elasticsearch/gc.log:utctime,pid,tags:filecount=32,filesize=64m\n".format(
                allocate, allocate, "{ES_", "TMPDIR}"
            )
        )
    time.sleep(1)
    subprocess.Popen(
        ["sudo", "/bin/systemctl", "daemon-reload"],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
    ).communicate()
    subprocess.Popen(
        ["sudo", "systemctl", "restart", "elasticsearch"],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
    ).communicate()
    subprocess.Popen(
        ["sudo", "systemctl", "restart", "logstash"],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
    ).communicate()
    subprocess.Popen(
        ["sudo", "systemctl", "restart", "kibana"],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
    ).communicate()
    time.sleep(1)
    subprocess.Popen(
        ["sudo", "updatedb"], stdout=subprocess.PIPE, stderr=subprocess.PIPE
    ).communicate()
    print(
        "   Kibana is available at:            127.0.0.1:5601"
    )  # adjust if custom location

if __name__ == "__main__":
    main()